本篇主要介绍目前实现的 3D姿态估计算法的实现；

1.主要的设计思路主要来自于之前的 2D姿态估计方法 sample_baseline 的方法，主要的基础网络其实是ResNet残差网络，在C5之后采用的反卷积操作，直接进行高分辨率的恢复，之前CPN网络中已经证明高分辨率的特征对于关节点的定位很重要；

2.所以设计的基础网络是 ResNet50到C5特征部分的层，后续增加 3个反卷积操作，进行特征的上
采样操作，得到高分辨率特征；

3.之前3D姿态估计方法，往往直接设计回归模型，直接进行3D关节点的深度值回归，本篇主要的设计
来自于<StarMap for Category-Agnostic Keypoint and Viewpoint Estimation>【StarMap_model.jpg】
【该篇论文主要是研究桌椅角点的论文，同时利用角点的热图 和 深度图来表示单位空间3D空间的点】

4.最终的模型其实是在 2D姿态估计的基础上，增加两个卷积操作，一个是回归关节点的热图；一个是回归关节点深度的热图；最终的 3D单位坐标x,y是 关节点热图(16个)每张热图上的峰值位置，根据峰值位置的坐标，到深度热图上找对应的坐标点的值，该值就是对应的深度预测值；

5.这边主要介绍下关于损失的计算 包括2D损失 和 3D损失？？
    针对 2D姿态的损失，模型在训练迭代时，选用的是关于热图之间的 L2损失，预测的关节点热图与真实坐标的热图【这边是通过高斯滤波器生成的】
    
    模型测试时，直接根据2D姿态的热图，每张热图上的峰值位置就是关节点最优可能的坐标位置；

    针对 3D姿态的损失计算：主要包括 几何损失 和 非几何损失：
1.非几何损失：其实就是预测的深度值 与 真实的深度值 之间计算 smooth_L1损失，并最小化该损失；
2.几何损失： 将人体骨架分为 4组，每组股价中不同的关节长度的权重不一样，求每组关节长度相对于
每组平均长度的比值，并乘以相关的系数；【主要思想：就是预测出的骨架尽量符合人体的比例】

6.最终的评价指标？？？？
    最终的指标论文中都是真实场景中，骨架长度的平均误差距离【单位:mm】，预测的3d与真实3d坐标计算相关的关节长度，对应关节部分计算L2距离作为偏差距离；最终求得所有关节即骨架的平均误差值；

7.关于关节点之间的夹角是否能提高性能？？？？
    后续将 部分关节点之间的夹角尝试作为损失，加入到最终的损失计算，更新模型参数，发现结果优化的很少；

8.关于不完整人体的关节点定位？？？？
    其实对于不完整人体，最终也会预测16个关节点，但如何进行筛选呢？主要是特征图中的值都是概率值，表示这个点是关节点的概率，每个特征图最终选择的都是峰值（最大概率），后续发现，那些不存在的关节点，虽然有概率值，但是峰值概率都很小，可以通过设置阈值对其进行过滤；

9.关于最终模型的大小及速度简介？？？
    模型大小在 130M左右，能同时完成人体的2D和3D姿态估计，速度大概在20ms左右，能完成实时性；模型测试时，该模型的输入其实是一个人体图片，且需要匹配模型的输入大小，后续还需加入人体检测模块；
    所以，后续加入了人体检测模块，具体的做法尝试了两种方式，一种是利用yolov3训练了人体检测模型；第二种为了加入速度，使用MobileNet-SSD在VOC和COCO上，训练得到人体检测模型【速度更快】；
