1.之前介绍过了 关于人体姿态估计的集中方法及网络结构，具体的代码实现及相关的文档，由于公司
相关协议，并未上传，主要列举其中的一些核心思想说明；可以参考相应论文及进行实现；

2.由于人体姿态估计目前在安防中涉猎比较多，比如摔倒检测，暴力事件的预警或者商场、地铁的姿态的
检测，或者驾驶中人的状态检测，当然还可以用于动作指导(如锻炼课程的动作规范指导、或者康复指导等)；

3.人体姿态估计多数是进行2d姿态的估计，但是日常世界中，3d姿态的研究和3d的场景具有更真实的场景，
在诸如动作指导中，在空间上进行估计，对于某些活动或者姿态具有更好的规范指导作用；

4.所以，后续研究了关于2d姿态转3d姿态的相关模型；

关于相关数据集的描述：
    1.之前的 2D人体姿态估计，目前使用比较多的是 MPII数据集 和 COCO姿态估计数据集

    2.对于3D数据集，目前使用比较最多的 Human3.6M 数据集，数据集很大；该数据集的使用需官方申请，
    目前也只是拿到一部分数据集，原始数据集不能用于商业等做了限制；
    【datasets：http://vision.imar.ro/human3.6m/description.php】

5.本篇主要描述项目中两种实现方法：
（1）Towards 3D Human Pose Estimation in the Wild: a Weakly-supervised Approach
（2）主要是针对上述方法的改进，替换基础网络，并重新引入新方法进行深度估计；


相关问题说明：

1.既然是做3D姿态估计，为什么要使用2D姿态估计网络？？？？
    我么都知道，图片分类中常常使用预训练模型，这边的思想其实有相似的意义，相比于直接学习
人体的3D姿态，基于2D姿态估计网络的预训练模型，对于最终3D的姿态估计有重要作用；

2.关于模型的测试？？
    之前在训练的stacked hourglass网络上进行姿态估计，发现人体姿态不准，后面经过数据集的
处理代码发现，之前的 MPII数据集 和 human3.6M数据集都是处理成 以人为中心的方形图片，之后
进行人体姿态估计时，发现姿态估计比较准确；

3.如何实现任意一张图片的姿态估计？？？
    整个流程依旧采用自上而下的方法，首先进行人体检测； 由于检测的人体不一定是方形的区域，
需对检测人体区域进行 仿射变换得到方形区域，输入到网络进行2D人体姿态估计，将检测的结果，再
通过 仿射变换的反变换得到在原图中的2D姿态估计；

4.关于human3.6M数据集中的人体3D数据集的处理？？？
    human3.6M中关于深度值，其实是飞行时间，后面进行了坐标转换，都是相对于 骨盆点的相对坐标；
最后所有的坐标点，都是进行了归一化的操作，三维度的坐标都是相对于输入尺度的归一化坐标，这样
训练出来的模型更加稳定，且能更好的更新模型参数；

5.关于模型中的 3D数据，以及最终的预测值的处理 和 指标评价？？？？？
    关于模型中数据都会预处理成相对于骨盆点的位置信息，模型在整个流程中训练 和 最终预测的值
都是相对于骨盆点的值；
    关于评价指标，2D数据中其实是以 预测关节点与真实关节点的误差值的小于阈值的比例作为最终的
ACC计算评价指标；而3D数据中的评价指标是 预测的关节点长度与真实关节点长度之前差的均值【单位:mm】
目前效果比较好的论文中，不同关节间的误差值其实是不一样的，在human3.6M val数据集上，总的均值
大概在 60mm左右；
    预测的3D坐标，其实是规范坐标系【单位化】中人体的关节点坐标，后续会根据真实场景的关节总
长度 与 单位化坐标系中预测骨架的关节总长度 进行等比的放大操作；同时需要 将相对坐标恢复到真
实场景中的坐标值；

6.关于热图的介绍【对于不完整人体，点的过滤操作】？？？？？
    其实，每张热图中的值都是概率值，概率值越大，表示该点是关节点的概率越大；后续在针对不完整
人体进行姿态估计时，最终也会得到16张热图，但是对于图片中不存在的点也会进行标注，在查看值发现，
这些点的概率值都非常小，可以通过阈值进行过滤操作；
